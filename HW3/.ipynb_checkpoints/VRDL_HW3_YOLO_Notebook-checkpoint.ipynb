{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DK957w7LLLh9"
   },
   "source": [
    "# Selected Topics in Visual Recognition in Deep Learning Exercise 3\n",
    "\n",
    "**Student name:** Fu-sung Kim-Benjamin Tang\n",
    "\n",
    "**Student ID:** 0845058\n",
    "\n",
    "**Github link of Homework 3:** https://github.com/kimbold/VRDL_2019/tree/master/HW3\n",
    "\n",
    "**References:**\n",
    "The code I used in this work reuses a lot of partly modified code from this repository: https://github.com/penny4860/Yolo-digit-detector\n",
    "\n",
    "**Speed benchmark:**\n",
    "Processing one image for digit prediction and localization takes 114 ms as tested on Google Colabs TPU which processed the data in general faster than the GPU in my tests:\n",
    "![alt text](https://raw.githubusercontent.com/kimbold/VRDL_2019/master/HW3/GoogleColabBenchmark_TPU_Performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodology:**\n",
    "\n",
    "To solve this digit detection exercise, the YOLO v2 network was trained on the provided svhn data and then used to classify the test dataset. For the computation the weights from the training were loaded into google colab and the speed was benchmarked and results stored into the .json file for the submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preprocess:**\n",
    "\n",
    "The datasets have been loaded into Google Colab and were extracted. Then the .mat/h5 file was processed to create an xml file for each image for the annotations (label and positions).\n",
    "Based on that it was possible to train the network and store the weights for later usage afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model architecture:** \n",
    "\n",
    "For this task I utilized the darknet yolo v2 architecture. As described in the yolo9000 (yolo v2) paper [here](https://arxiv.org/pdf/1612.08242v1.pdf), the YOLO framework uses a custom network based on the Googlenet architecture. It is a fully connected convolutional neural network and can be visually represented:\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/kimbold/VRDL_2019/master/HW3/YoloArchitectureFromYoloPaper.png) \n",
    "(This is a figure from the YOLO paper [here](https://www.semanticscholar.org/paper/You-Only-Look-Once%3A-Unified%2C-Real-Time-Object-Redmon-Divvala/f8e79ac0ea341056ef20f2616628b3e964764cfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters:**\n",
    "\n",
    "*   \"architecture\": \"ResNet50\"\n",
    "*   \"input_size\":           416\n",
    "* \"anchors\":              [0.57273, 0.677385, 1.87446, 2.06253,3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "* \"labels\":               [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "*   \"coord_scale\" : \t\t1.0\n",
    "*   \"class_scale\" : \t\t1.0\n",
    "* \"object_scale\" : \t\t5.0\n",
    "* \"no_object_scale\" : \t1.0\n",
    "* weights: \"svhn/weights.h5\"\n",
    "* \"actual_epoch\":         25,\n",
    "* \"train_times\":          5,\n",
    "* \"valid_times\":          1,\n",
    "* \"batch_size\":           16,\n",
    "* \"learning_rate\":        1e-4,\n",
    "* \"saved_folder\":   \t\t\"svhn\",\n",
    "* \"jitter\":\t\t\t\ttrue,\n",
    "* \"first_trainable_layer\": \"input_1\",\n",
    "* \"is_only_detect\" : \t\tfalse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "Overall the model performed quite well and managed to detect and a lot of images correctly. \n",
    "\n",
    "But there are also several instances when the network could not detect any images at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Uk6RQYmABKBY",
    "outputId": "901f67f3-d73b-46ca-dc56-08b93dc81b6f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kimbold/VRDL_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKypR3EjTRZQ"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "####################################################\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BtQbRIbLBfab",
    "outputId": "d61d7a1a-1b0a-45d2-c0f9-3396ad12d2b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/VRDL_2019/HW3\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Switch to HW3 folder in Google Colab after \n",
    "# cloning my github repository\n",
    "####################################################\n",
    "\n",
    "%cd VRDL_2019/HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "XAEs7pE6M3Pu",
    "outputId": "7a7ac39d-3931-489b-a5f5-6c11a4931410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DryVeYEC5mlo0YFHltN6EhO4zFuTIvNn\n",
      "To: /content/VRDL_2019/HW3/weights.h5\n",
      "285MB [00:01, 234MB/s]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Download weights that have been stored after training\n",
    "####################################################\n",
    "\n",
    "!pip install gdown\n",
    "!gdown https://drive.google.com/uc?id=1DryVeYEC5mlo0YFHltN6EhO4zFuTIvNn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "DxPs48KsONdD",
    "outputId": "44068614-74b5-463d-fb26-33e11ce5c4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GV4TLocxFcsR8QPdM-rP8RoOB2vjs_E_\n",
      "To: /content/VRDL_2019/HW3/test.zip\n",
      "272MB [00:01, 224MB/s]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Download test data as specified by HW3\n",
    "####################################################\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1GV4TLocxFcsR8QPdM-rP8RoOB2vjs_E_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TZGZJ9CmSGNG",
    "outputId": "17d9c445-24ea-476d-a4a0-104fb005fb69"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Install required libraries via pip in Google colab\n",
    "####################################################\n",
    "\n",
    "!pip install tensorflow==1.14.0\n",
    "!pip install keras==2.1.1\n",
    "!pip install imgaug==0.2.6\n",
    "!pip install opencv-python\n",
    "!pip install Pillow\n",
    "!pip install requests\n",
    "!pip install tqdm\n",
    "!pip install sklearn\n",
    "!pip install pytest-cov\n",
    "!pip install codecov\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDOF4j67GHYk"
   },
   "source": [
    "**Load svhn dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00BvTMLsQ4mz"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# If training is enabled, also load training data\n",
    "# But currently training is disabled \n",
    "####################################################\n",
    "\n",
    "training=0\n",
    "if(training==1):\n",
    "  !wget http://ufldl.stanford.edu/housenumbers/train.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vxnVASQDtFp"
   },
   "source": [
    "**Extract dataset files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T10:14:14.386171Z",
     "start_time": "2019-11-28T10:14:14.378161Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ArqYzlbOD6tf",
    "outputId": "5eeaa3df-6b33-4018-9611-8e1ffbc4474f"
   },
   "outputs": [],
   "source": [
    "!unzip test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXmj3ctIJZNV"
   },
   "source": [
    "**Import required modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "sae1hDFCJYto",
    "outputId": "faeb070c-4f37-4b88-f357-30cf61a37c2b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from yolo.frontend import create_yolo, get_object_labels\n",
    "import xml.etree.cElementTree as ET\n",
    "import h5py\n",
    "from lxml import etree\n",
    "import tables\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from yolo.frontend import create_yolo\n",
    "from yolo.backend.utils.box import draw_scaled_boxes\n",
    "from yolo.backend.utils.annotation import parse_annotation\n",
    "from yolo.backend.utils.eval._box_match import BoxMatcher\n",
    "\n",
    "import os\n",
    "import yolo\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDPsoJWpjU4w"
   },
   "source": [
    "**Define methods to load annotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E52R15bvjUTU"
   },
   "outputs": [],
   "source": [
    "def get_name(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])\n",
    "\n",
    "def keys(f):\n",
    "    return [key for key in f.keys()]\n",
    "\n",
    "def get_bbox(index, hdf5_data):\n",
    "  \"\"\"\n",
    "  The box data contains width and height of the box as well as the upper left corner.\n",
    "  By supplying the distance from the left border and top border, the upper left point can be identified.\n",
    "  \"\"\"\n",
    "  attrs = {}\n",
    "  item = hdf5_data['digitStruct']['bbox'][index].item()\n",
    "  for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "      attr = hdf5_data[item][key]\n",
    "      values = [hdf5_data[attr.value[i].item()].value[0][0]\n",
    "                for i in range(len(attr))] if len(attr) > 1 else [attr.value[0][0]]\n",
    "      attrs[key] = values\n",
    "  return attrs\n",
    "\n",
    "def prettyPrintXml(xmlFilePathToPrettyPrint):\n",
    "    parser = etree.XMLParser(resolve_entities=False, strip_cdata=False)\n",
    "    document = etree.parse(xmlFilePathToPrettyPrint, parser)\n",
    "    document.write(xmlFilePathToPrettyPrint, pretty_print=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "# Define replacement strings for different operating systems\n",
    "WINDOWS_LINE_ENDING = b'\\r\\n'\n",
    "UNIX_LINE_ENDING = b'\\n'\n",
    "\n",
    "def replace_Unix_with_Windows_in_XLM(xmlFilePath):\n",
    "    with open(xmlFilePath, 'rb') as open_file:\n",
    "      content = open_file.read()\n",
    "\n",
    "    content = content.replace(UNIX_LINE_ENDING,WINDOWS_LINE_ENDING)\n",
    "\n",
    "    with open(xmlFilePath, 'wb') as open_file:\n",
    "        open_file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APez-2Tf1Aet"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# If training is enabled, the test annotations have \n",
    "# to be created to train the model \n",
    "####################################################\n",
    "if(training==1):\n",
    "  directory = \"tests/dataset/svhn/test_anns\"\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUdKDwCSjdN1"
   },
   "source": [
    "**Load annotations for training**\n",
    "\n",
    "The annotations are read from the h5 file and then written to xml files for each picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-SGxwrU-JE-"
   },
   "outputs": [],
   "source": [
    "if(training==1):\n",
    "  # Need to define method to read .mat data and then write annotation files for each picture\n",
    "  filename = \"train/digitStruct.mat\"\n",
    "\n",
    "  f = h5py.File(filename,'r')\n",
    "\n",
    "  # Iterate through all images to create the annotation file\n",
    "  for image in range(f['digitStruct']['bbox'].shape[0]):\n",
    "    #annotation\n",
    "    root = ET.Element(\"annotation\")\n",
    "\n",
    "    #Get image annotation data\n",
    "    size_data = get_bbox(image, f)\n",
    "\n",
    "    #filename\n",
    "    filename = get_name(image,f)\n",
    "    doc = ET.SubElement(root, \"filename\").text = filename\n",
    "\n",
    "    # For each detected digit, add the data for the box for it\n",
    "    object_list = [[] for _ in range(len(size_data['label']))]\n",
    "    bndbox = [[] for _ in range(len(size_data['label']))]\n",
    "\n",
    "    for number in range(len(size_data['label'])):\n",
    "      object_list[number] = ET.SubElement(root, \"object\")\n",
    "      ET.SubElement(object_list[number], \"name\").text = str(int(size_data['label'][number]))\n",
    "\n",
    "      bndbox[number] = ET.SubElement(object_list[number], \"bndbox\")\n",
    "      ET.SubElement(bndbox[number], \"xmin\").text = str(int(size_data['left'][number]))\n",
    "      ET.SubElement(bndbox[number], \"ymin\").text = str(int(size_data['top'][number]))\n",
    "      ET.SubElement(bndbox[number], \"xmax\").text = str(int(size_data['width'][number]+size_data['left'][number]))\n",
    "      ET.SubElement(bndbox[number], \"ymax\").text = str(int(size_data['height'][number]+size_data['top'][number]))\n",
    "    \n",
    "    tree = ET.ElementTree(root)\n",
    "\n",
    "    #Write xml \n",
    "    tree.write(\"tests/dataset/svhn/anns/\"+str(image+1)+\".xml\")\n",
    "    prettyPrintXml(\"tests/dataset/svhn/anns/\"+str(image+1)+\".xml\")\n",
    "    replace_Unix_with_Windows_in_XLM(\"tests/dataset/svhn/anns/\"+str(image+1)+\".xml\")\n",
    "\n",
    "  # For some reason google colab always showed an error with this checkpoint directory after this operation\n",
    "  # So I had to delete it\n",
    "  if os.path.exists('tests/dataset/svhn/anns/.ipynb_checkpoints'):\n",
    "    os.rmdir('tests/dataset/svhn/anns/.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6X3TEskAJUso"
   },
   "source": [
    "**Train yolo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkTZ6qXmJTwA"
   },
   "outputs": [],
   "source": [
    "#Train and validate YOLO_v2 model on any dataset\n",
    "def setup_training(config_file):\n",
    "    \"\"\"make directory to save weights & its configuration \"\"\"\n",
    "    import shutil\n",
    "    with open(config_file) as config_buffer:\n",
    "        config = json.loads(config_buffer.read())\n",
    "    dirname = config['train']['saved_folder']\n",
    "    if os.path.isdir(dirname):\n",
    "        print(\"{} is already exists. Weight file in directory will be overwritten\".format(dirname))\n",
    "    else:\n",
    "        print(\"{} is created.\".format(dirname, dirname))\n",
    "        os.makedirs(dirname)\n",
    "    print(\"Weight file and Config file will be saved in \\\"{}\\\"\".format(dirname))\n",
    "    shutil.copyfile(config_file, os.path.join(dirname, \"config.json\"))\n",
    "    return config, os.path.join(dirname, \"weights.h5\")\n",
    "\n",
    "\n",
    "def train(conf=\"configs/from_scratch.json\"):\n",
    "  #path to configuration file\n",
    "\n",
    "    config, weight_file = setup_training(conf)\n",
    "    \n",
    "    if config['train']['is_only_detect']:\n",
    "        labels = [\"object\"]\n",
    "    else:\n",
    "        if config['model']['labels']:\n",
    "            labels = config['model']['labels']\n",
    "        else:\n",
    "            labels = get_object_labels(config['train']['train_annot_folder'])\n",
    "    print(labels)\n",
    "\n",
    "    # 1. Construct the model \n",
    "    yolo = create_yolo(config['model']['architecture'],\n",
    "                       labels,\n",
    "                       config['model']['input_size'],\n",
    "                       config['model']['anchors'],\n",
    "                       config['model']['coord_scale'],\n",
    "                       config['model']['class_scale'],\n",
    "                       config['model']['object_scale'],\n",
    "                       config['model']['no_object_scale'])\n",
    "\n",
    "    # 2. Load the pretrained weights (if any) \n",
    "    yolo.load_weights(config['pretrained']['full'], by_name=True)\n",
    "\n",
    "    # 3. actual training \n",
    "    yolo.train(config['train']['train_image_folder'],\n",
    "               config['train']['train_annot_folder'],\n",
    "               config['train']['actual_epoch'],\n",
    "               weight_file,\n",
    "               config[\"train\"][\"batch_size\"],\n",
    "               config[\"train\"][\"jitter\"],\n",
    "               config['train']['learning_rate'], \n",
    "               config['train']['train_times'],\n",
    "               config['train']['valid_times'],\n",
    "               config['train']['valid_image_folder'],\n",
    "               config['train']['valid_annot_folder'],\n",
    "               config['train']['first_trainable_layer'],\n",
    "               config['train']['is_only_detect'])\n",
    "    # loss: 2.1691, train batch jitter=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1TCZgELJ7Ew"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Here the entire network is trained and it takes \n",
    "# a long time depending on the configurations\n",
    "####################################################\n",
    "\n",
    "if(training==1):\n",
    "  train(conf=\"configs/from_scratch_custom.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iPc5Qr6et74"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Here only the last layer is fine tuned\n",
    "####################################################\n",
    "\n",
    "if(training==1):  \n",
    "  train(conf=\"configs/from_scratch2_custom.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QG9kQkl8dOa9"
   },
   "source": [
    "**After training the weights are stored in .h5 file**\n",
    "\n",
    "So now it is necessary to ensure that it is closed properly to avoid corruption.\n",
    "Not sure why exactly but it caused errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VNSA3mSdNzw"
   },
   "outputs": [],
   "source": [
    "# Closing all .hd5 files: https://stackoverflow.com/questions/29863342/close-an-open-h5py-data-file against corruption\n",
    "tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfqlOEoeKO9m"
   },
   "source": [
    "**Evaluate trained yolo digit detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T10:32:18.119571Z",
     "start_time": "2019-11-28T10:32:18.114578Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "A006i67dB9GR"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Define parameters\n",
    "####################################################\n",
    "\n",
    "DEFAULT_CONFIG_FILE = os.path.join(yolo.PROJECT_ROOT, \"svhn\", \"config.json\")\n",
    "DEFAULT_WEIGHT_FILE='/content/VRDL_2019/HW3/weights.h5'\n",
    "DEFAULT_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uNZi5mAWSz8"
   },
   "source": [
    "**Predict test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BL8mWdViR9Zj"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "####################################################\n",
    "# Define method to just build the network and load the weights\n",
    "# so that the speed can be benchmarked with just the prediction\n",
    "# and not the model loading as well\n",
    "####################################################\n",
    "\n",
    "def create_yolo_instance(conf=DEFAULT_CONFIG_FILE, weights=DEFAULT_WEIGHT_FILE):\n",
    "  with open(conf) as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "  \n",
    "  # 2. create yolo instance & predict\n",
    "  yolo = create_yolo(config['model']['architecture'],\n",
    "                     config['model']['labels'],\n",
    "                     config['model']['input_size'],\n",
    "                     config['model']['anchors'])\n",
    "  yolo.load_weights(weights)\n",
    "  return yolo\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Define method to predict the 13068 test images\n",
    "####################################################\n",
    "\n",
    "def predict_testdata(image_folder=\"test/\",conf=DEFAULT_CONFIG_FILE, weights=DEFAULT_WEIGHT_FILE, threshold=DEFAULT_THRESHOLD):\n",
    "\n",
    "      # Create list of dictionaries for submission\n",
    "      prediction_dictionaries = [{} for _ in range(1,13069)]\n",
    "\n",
    "\n",
    "      with open(conf) as config_buffer:\n",
    "          config = json.loads(config_buffer.read())\n",
    "\n",
    "      # 2. create yolo instance & predict\n",
    "      yolo = create_yolo(config['model']['architecture'],\n",
    "                        config['model']['labels'],\n",
    "                        config['model']['input_size'],\n",
    "                        config['model']['anchors'])\n",
    "      yolo.load_weights(weights)\n",
    "\n",
    "      # 3. read image\n",
    "      write_dname = \"detected\"\n",
    "      if not os.path.exists(write_dname): os.makedirs(write_dname)\n",
    "  \n",
    "      for i in range(1,13069):\n",
    "          # For each image, get the predicted labels, probabilities and boxes\n",
    "\n",
    "          img_path=image_folder+str(i)+\".png\"\n",
    "          print(img_path)\n",
    "          img_fname = os.path.basename(img_path)\n",
    "          image = cv2.imread(img_path)\n",
    "          boxes = [[]]\n",
    "          probs = []\n",
    "          labels = []\n",
    "          boxes, probs = yolo.predict(image, float(threshold))\n",
    "          labels = np.argmax(probs, axis=1) if len(probs) > 0 else [] \n",
    "            \n",
    "          try:\n",
    "            prediction_dictionaries[i-1]['bbox']=boxes.tolist()\n",
    "          except:\n",
    "            prediction_dictionaries[i-1]['bbox']=boxes\n",
    "\n",
    "          prediction_dictionaries[i-1]['score']=[np.max(probs[i]) for i in range(len(probs))]\n",
    "\n",
    "          try:\n",
    "            prediction_dictionaries[i-1]['label']=labels.tolist()\n",
    "          except:\n",
    "            prediction_dictionaries[i-1]['label']=labels\n",
    "\n",
    "          #print(prediction_dictionaries)\n",
    "          # 4. save detection result\n",
    "          image = draw_scaled_boxes(image, boxes, probs, config['model']['labels'])\n",
    "          output_path = os.path.join(write_dname, os.path.split(img_fname)[-1])\n",
    "          \n",
    "          cv2.imwrite(output_path, image)\n",
    "          #print(\"{}-boxes are detected. {} saved.\".format(len(boxes), output_path))\n",
    "    \n",
    "      #5. Write the list of dictionaries to a .json file for the submission\n",
    "      with open(\"0845058.json\", 'w') as f:\n",
    "        f.write(str(prediction_dictionaries))\n",
    "      \n",
    "      #6. Upload the .json file to google drive\n",
    "      file1 = drive.CreateFile()\n",
    "      file1.SetContentFile('0845058.json')\n",
    "      file1.Upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C64Xq90GMZ41"
   },
   "source": [
    "**Timing for one picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T10:13:54.431005Z",
     "start_time": "2019-11-28T10:13:54.424990Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gGNPpH7oONX7",
    "outputId": "1a7b66a7-7bb0-4937-8ec0-2c3f4379dbed"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "#Create yolo instance\n",
    "####################################################\n",
    "\n",
    "conf = os.path.join(yolo.PROJECT_ROOT, \"config_customized.json\")\n",
    "yolo = create_yolo_instance(conf=conf, weights=DEFAULT_WEIGHT_FILE)\n",
    "\n",
    "\n",
    "####################################################\n",
    "#Load image from test folder (unseen)\n",
    "####################################################\n",
    "\n",
    "image_folder=\"test/\"\n",
    "i=1 # load the first image\n",
    "img_path=image_folder+str(i)+\".png\"\n",
    "img_fname = os.path.basename(img_path)\n",
    "image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "L2qcNz-eMcDp",
    "outputId": "69918b6b-cf86-4b3a-adc8-234a0dfeb32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.99 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 114 ms per loop\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Benchmark the speed on google colab with TPU\n",
    "####################################################\n",
    "\n",
    "%%timeit\n",
    "yolo.predict(image, float(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T10:13:46.996989Z",
     "start_time": "2019-11-28T10:13:46.942000Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wcEpzb0cgEe0",
    "outputId": "87497977-c83e-48fc-ee17-9b95a81b0a32"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Dtect digits of the test data\n",
    "####################################################\n",
    "\n",
    "predict_testdata(conf=\"/content/VRDL_2019/HW3/testing.json\",image_folder=image_folder, weights=DEFAULT_WEIGHT_FILE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "VRDL_HW3_YOLO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
